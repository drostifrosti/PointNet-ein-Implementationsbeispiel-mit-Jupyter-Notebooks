{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers import Convolution1D, MaxPooling1D, BatchNormalization\n",
    "from keras.layers import Lambda, concatenate\n",
    "#from keras.utils import np_utils\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_mul(A, B):\n",
    "    return tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_dim(global_feature, num_points):\n",
    "    return tf.tile(global_feature, [1, num_points, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_h5(h5_filename):\n",
    "    f = h5py.File(h5_filename)\n",
    "    data = f['data'][:]\n",
    "    label = f['label'][:]\n",
    "    return (data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_point_cloud(batch_data):\n",
    "    \"\"\" Randomly rotate the point clouds to augument the dataset\n",
    "        rotation is per shape based along up direction\n",
    "        Input:\n",
    "          BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "          BxNx3 array, rotated batch of point clouds\n",
    "    \"\"\"\n",
    "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
    "    for k in range(batch_data.shape[0]):\n",
    "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
    "        cosval = np.cos(rotation_angle)\n",
    "        sinval = np.sin(rotation_angle)\n",
    "        rotation_matrix = np.array([[cosval, 0, sinval],\n",
    "                                    [0, 1, 0],\n",
    "                                    [-sinval, 0, cosval]])\n",
    "        shape_pc = batch_data[k, ...]\n",
    "        rotated_data[k, ...] = np.dot(shape_pc.reshape((-1, 3)), rotation_matrix)\n",
    "    return rotated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jitter_point_cloud(batch_data, sigma=0.01, clip=0.05):\n",
    "    \"\"\" Randomly jitter points. jittering is per point.\n",
    "        Input:\n",
    "          BxNx3 array, original batch of point clouds\n",
    "        Return:\n",
    "          BxNx3 array, jittered batch of point clouds\n",
    "    \"\"\"\n",
    "    B, N, C = batch_data.shape\n",
    "    assert(clip > 0)\n",
    "    jittered_data = np.clip(sigma * np.random.randn(B, N, C), -1 * clip, clip)\n",
    "    jittered_data += batch_data\n",
    "    return jittered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points in each sample\n",
    "num_points = 1024\n",
    "\n",
    "# shapes and categories\n",
    "sList = {'Airplane': 4, 'Bag': 2, 'Cap': 2, 'Car': 3, 'Chair': 4,\n",
    "         'Earphone': 2, 'Guitar': 3, 'Knife': 2, 'Lamp': 3, 'Laptop': 1,\n",
    "         'Motorbike': 5, 'Mug': 1, 'Pistol': 3, 'Rocket': 3, 'Skateboard': 2, 'Table': 2}\n",
    "# chosen shape\n",
    "s = 'Guitar'\n",
    "# number of categories\n",
    "k = sList[s]\n",
    "print(k)\n",
    "# define optimizer\n",
    "adam = optimizers.Adam(lr=0.001, decay=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------ Pointnet Architecture\n",
    "# input_Transformation_net\n",
    "input_points = Input(shape=(num_points, 3))\n",
    "x = Convolution1D(64, 1, activation='relu',\n",
    "                  input_shape=(num_points, 3))(input_points)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(128, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Convolution1D(1024, 1, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D(pool_size=num_points)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(9, weights=[np.zeros([256, 9]), np.array([1, 0, 0, 0, 1, 0, 0, 0, 1]).astype(np.float32)])(x)\n",
    "input_T = Reshape((3, 3))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': input_T})(input_points)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(64, 1, input_shape=(num_points, 3), activation='relu')(g)\n",
    "g = BatchNormalization()(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature transformation net\n",
    "f = Convolution1D(64, 1, activation='relu')(g)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(128, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Convolution1D(1024, 1, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = MaxPooling1D(pool_size=num_points)(f)\n",
    "f = Dense(512, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(256, activation='relu')(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Dense(64 * 64, weights=[np.zeros([256, 64 * 64]), np.eye(64).flatten().astype(np.float32)])(f)\n",
    "feature_T = Reshape((64, 64))(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward net\n",
    "g = Lambda(mat_mul, arguments={'B': feature_T})(g)\n",
    "seg_part1 = g\n",
    "g = Convolution1D(64, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(128, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)\n",
    "g = Convolution1D(1024, 1, activation='relu')(g)\n",
    "g = BatchNormalization()(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_feature\n",
    "global_feature = MaxPooling1D(pool_size=num_points)(g)\n",
    "global_feature = Lambda(exp_dim, arguments={'num_points': num_points})(global_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point_net_seg\n",
    "c = concatenate([seg_part1, global_feature])\n",
    "c = Convolution1D(512, 1, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Convolution1D(256, 1, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Convolution1D(128, 1, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "c = Convolution1D(128, 1, activation='relu')(c)\n",
    "c = BatchNormalization()(c)\n",
    "prediction = Convolution1D(k, 1, activation='softmax')(c)\n",
    "# --------------------------------------------------end of pointnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Model(inputs=input_points, outputs=prediction)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRAIN points and labels\n",
    "path = os.getcwd()\n",
    "train_path = os.path.join(path, \"Seg_Prep\")\n",
    "filename = s + \".h5\"\n",
    "print(train_path)\n",
    "print(filename)\n",
    "train_points = None\n",
    "train_labels = None\n",
    "cur_points, cur_labels = load_h5(os.path.join(train_path, filename))\n",
    "\n",
    "train_labels = cur_labels\n",
    "train_points = cur_points\n",
    "\n",
    "train_points_r = train_points.reshape(-1, num_points, 3)\n",
    "train_labels_r = train_labels.reshape(-1, num_points, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TEST points and labels\n",
    "test_path = os.path.join(path, \"Seg_Prep_test\")\n",
    "filename = s + \".h5\"\n",
    "print(test_path)\n",
    "print(filename)\n",
    "test_points = None\n",
    "test_labels = None\n",
    "cur_points, cur_labels = load_h5(os.path.join(test_path, filename))\n",
    "\n",
    "test_labels = cur_labels\n",
    "test_points = cur_points\n",
    "\n",
    "test_points_r = test_points.reshape(-1, num_points, 3)\n",
    "test_labels_r = test_labels.reshape(-1, num_points, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train and evaluate the model\n",
    "'''\n",
    "\n",
    "# train model\n",
    "for i in range(1, 101):\n",
    "    # rotate and jitter point cloud every epoch\n",
    "    train_points_rotate = rotate_point_cloud(train_points_r)\n",
    "    train_points_jitter = jitter_point_cloud(train_points_rotate)\n",
    "    model.fit(train_points_jitter, train_labels_r, batch_size=32, epochs=1, shuffle=True, verbose=1)\n",
    "    e = \"Current epoch is:\" + str(i)\n",
    "    print(e)\n",
    "    # evaluate model\n",
    "    if i % 5 == 0:\n",
    "        score = model.evaluate(test_points_r, test_labels_r, verbose=1)\n",
    "        print('Test loss: ', score[0])\n",
    "        print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "visualization\n",
    "'''\n",
    "# select one test data to visualize\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "v_points = test_points_r[1:2,:,:]\n",
    "pred = model.predict(v_points)\n",
    "pred = np.squeeze(pred)\n",
    "v_points = np.squeeze(v_points)\n",
    "pred = pred.tolist()\n",
    "color = ['r', 'g', 'c', 'y', 'm']\n",
    "m= ['o', 'v', '<', '>', 's']\n",
    "for i in range(v_points.shape[0]):\n",
    "    xs = v_points[i,0]\n",
    "    ys = v_points[i,1]\n",
    "    zs = v_points[i,2]\n",
    "    ind = pred[i].index(max(pred[i]))\n",
    "    ax.scatter(xs, ys, zs, c=color[ind], marker=m[ind])\n",
    "\n",
    "ax.set_xlim3d(-0.3,0.3)\n",
    "ax.set_ylim3d(-0.3,0.3)\n",
    "ax.set_zlim3d(-0.3,0.3)    \n",
    "    \n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_points_r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
